```{r setup_genomic, include=FALSE}
rm(list = ls()) ; invisible(gc()) ; set.seed(42)
library(knitr)
library(parallel)
library(Biostrings)
library(rBLAST)
library(tidyverse)
theme_set(bayesplot::theme_default())
opts_chunk$set(
  echo = F, message = F, warning = F, fig.height = 6, fig.width = 8,
  cache = T, cache.lazy = F)
path <- "~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/"
```

# Genomic data

For neutral genomic data (see figure\@ref(fig:seqTree)) we have different sequences available:

* The African genome scaffolds from @Olsson2017
* The Guianan scaffolds from Scotti *et al (in prep)*
* The Guianan sequences from @Torroba-Balmori2017

The idea is to pool scaffolds from @Olsson2017 and Ivan *et al (in prep)* and try to filter redundances by creating extended scaffolds with `Newbler` and `CABOG` (see @Olsson2017). Then we wish to use longest scaffolds (>500 kpb due to assemby issues with Guianan scaffolds) that have good correspondance with @Torroba-Balmori2017 data. We will assess correspondance by blasting @Torroba-Balmori2017 sequences on previously obtained extended scaffolds with `blat`. Processing will be done in a new folder called `Ivan_Olsson_pool`.

## Scaffolds from Scotti *et al (in prep)*

We first need to rename scaffolds to pull theim together. For all scaffolds we will use following code : **Ivan_2018_[file name without .scafSeq]_[scaffold name]**. All scaffolds will be saved with the same name file with extension `.Ivan.renamed.scafSeq`.

```{r scaffoldsIvan, eval=F, echo=T}
path_Ivan <- file.path(path, "Ivan_2018")
dir.create(file.path(path, "Ivan_Olsson_pool"))
dir.create(file.path(path, "Ivan_Olsson_pool", "all_scaffolds"))
files <- list.files(path_Ivan)
files <- files[grep("scafSeq$", files)]
sapply(files, 
       function(file){
         scf <- readDNAStringSet(file.path(path_Ivan, file))
         names(scf) <- paste0("Ivan_2018_", gsub(".scafSeq", "", file), "_", names(scf))
         writeXStringSet(scf, file.path(path, "Ivan_Olsson_pool", "all_scaffolds",
                                        paste0(gsub(".scafSeq", "", file), ".Ivan.renamed.scafSeq")))
       } ,
       simplify = F)
```

## Scaffolds from @Olsson2017

We renamed scaffolds from Olsson using following code : **Olsson_2017_[scaffold name]**. All scaffolds will be saved with the same name file with extension `.Olsson.renamed.scafSeq`.

```{r scaffoldsOlsson, echo=T, fig.cap="Distribution of scaffolds by length in bp.", fig.height=4}
path_Olsson <- file.path(path, "Olsson_2016")
scf <- readDNAStringSet(file.path(path_Olsson, "symph_genome.fa"))
data.frame(width = width(scf)) %>% 
  ggplot(aes(width)) +
  geom_histogram() +
  scale_y_log10() +
  geom_vline(xintercept = 5000) +
  xlab("Scaffold width")
names(scf) <- paste0('Olsson_2017_', names(scf))
writeXStringSet(scf, file.path(path, "Ivan_Olsson_pool", "all_scaffolds",
                               paste0("symph_genome", ".Olsson.renamed.fa")))
rm(scf)
```

## Extended scaffolds creation

We will try to assemble scaffolds with [quickmerge](https://github.com/mahulchak/quickmerge) considering @Olsson2017 as the reference assembly and Scotti *et al (in prep)* as the query assembly. As we do not seek high quality merge, because we only use it to blast sequences from @Torroba-Balmori2017 to identify regions for probes design, we will run only one time `quickmerge` (but see wiki for more instructions on how to build high quality merged asssembly). `nucmer` seems limited by memory size on local machine, we will thus run the script on [genotoul](http://bioinfo.genotoul.fr/).

```{bash assemblyMerge, eval=F, echo=T}
cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_Olsson_pool
cat all_scaffolds/*.Olsson.renamed.fa > Olsson2017_scaffolds.fa 
cat all_scaffolds/*.Ivan.renamed.scafSeq > Ivan2018_scaffolds.fa
cat Ivan2018_scaffolds.fa Olsson2017_scaffolds.fa > scaffolds.fa
perl ~/Tools/miscperlscripts/split.scaffolds.to.contigs.pl -i scaffolds.fa -o contigs.fa 
nucmer -l 100 -prefix out Olsson2017_scaffolds.fa Ivan2018_scaffolds.fa
delta-filter -i 95 -r -q out.delta > out.rq.delta
~/Tools/quickmerge/quickmerge -d out.rq.delta -q Ivan2018_scaffolds.fa -r Olsson2017_scaffolds.fa -hco 5.0 -c 1.5 -l n -ml m
# ~/Tools/quickmerge/merge_wrapper.py Ivan2018_scaffolds.fa Olsson2017_scaffolds.fa
```

**I got some issues to use `mummer` and `quickmerge` both on local machine and genotoul cluster. In waiting, I suggest to use directly all scaffolds from @Olsson2017 and Scotti *et al (in prep)* puled together. We will use three blast database: (i) all scaffolds, (ii) scaffolds with a length > 500bp, and (iii) scaffolds with a length > 1 kbp.**

## Reads blast from @Torroba-Balmori2017

We will use [rBLAST](https://github.com/mhahsler/rBLAST) and `blastn` to blast @Torroba-Balmori2017 sequences on extended scaffolds from @Olsson2017 and Scotti *et al (in prep)*. We first need to prepare extended scaffolds as a blast data base with `makeblastdb`. Then we used scaffolds with highest blast match.

```{bash blastDB, eval=F, echo=T}
cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_Olsson_pool
makeblastdb -in scaffolds.fa -parse_seqids -dbtype nucl
seqtk seq -a ~/Documents/BIOGECO/PhD/data/Symphonia_Torroba/raw/raw/* > reads_Torroba.fa
```

```{r readNames, eval=F, echo=T}
reads <- readDNAStringSet(file.path(path, "Ivan_Olsson_pool", "reads_Torroba.fa"))
names(reads) <- gsub(" ","", names(reads))
writeXStringSet(reads, file.path(path, "Ivan_Olsson_pool", "reads_Torroba.fa"))
rm(reads)
```

```{bash blast, eval=F, echo=T}
blastn -query reads_Torroba.fa -db scaffolds_db/scaffolds.fa -outfmt 6 -num_alignments 1 -out blast_result.txt
```

**`blastn` with all reads is very long due to the huge amount of queries ! We will try to work first with consensus sequences from reads (next part).**

## Consensus blast from @Torroba-Balmori2017 reads

To reduce the amount of queries, we will use the consensus sequence for French Guianan reads from @Torroba-Balmori2017 previously assembled with `ipyrad`. As a first brutal approach we only keep the first sequence of the consensus loci file and transform it to fasta (see `loci2fa.py` script below). We then blast those consensus sequences on scaffolds data bases (all, > 0.5 kbp, > 1 kbp) with `blastn`.

```{bash blastDB2, echo=T, eval=F}
perl ~/Tools/SeqFilter/bin/SeqFilter -l 500 scaffolds.fa --out scaffolds_500.fa
makeblastdb -in scaffolds_500.fa -parse_seqids -dbtype nucl
perl ~/Tools/SeqFilter/bin/SeqFilter -l 1000 scaffolds.fa --out scaffolds_1000.fa
makeblastdb -in scaffolds_1000.fa -parse_seqids -dbtype nucl
```

```{python loci2fa, echo=T, eval=F}
infile = open("symphoGbS2.loci", "r")
outfile = open("symphoGbS2.firstline.fasta", "w")
loci = infile.read().split("|\n")[:-1]
for loc in loci:
    reads = loc.split("\n")
    name, seq = reads[0].split()
    print >>outfile, ">"+name+"\n"+seq
outfile.close()
```


```{r readNames2, eval=F, echo=T}
system("cat symphoGbS2.firstline.fasta | tr - N >> symphoGbS2.firstline.corr.fasta")
reads <- readDNAStringSet(file.path(path, "Ivan_Olsson_pool", "symphoGbS2.firstline.corr.fasta"))
names(reads) <- paste0(names(reads), ".", seq_len(length(reads)))
writeXStringSet(reads, file.path(path, "Ivan_Olsson_pool", "symphoGbS2.firstline.corr.fasta"))
```

```{bash blast2, echo=T, eval=F}
blastn -query symphoGbS2.firstline.corr.fasta -db scaffolds_1000_db/scaffolds_1000.fa -outfmt 6 -num_alignments 1 -out blast_result_firstline_1000.txt
blastn -query symphoGbS2.firstline.corr.fasta -db scaffolds_500_db/scaffolds_500.fa -outfmt 6 -num_alignments 1 -out blast_result_firstline_500.txt
blastn -query symphoGbS2.firstline.corr.fasta -db scaffolds_db/scaffolds.fa -outfmt 6 -num_alignments 1 -out blast_result_firstline.txt
```

```{r selection, eval=F, echo=T}
blast <- read_tsv(file.path(path, "Ivan_Olsson_pool", 
                            "blast_result_firstline.txt"), col_names = F)
names(blast) <- c("Read", "Scaffold", "Perc_Ident", "Alignment_length", "Mismatches",
                  "Gap_openings", "R_start", "R_end", "S_start", "S_end", "E", "Bits")
write_file(paste(unique(blast$Scaffold), collapse = "\n"), 
           file.path(path, "Ivan_Olsson_pool", "selected_scaffolds.list"))
system("seqtk subseq scaffolds.fa selected_scaffolds.list >> selected_scaffolds.fa")
```

We obtained one short scaffolds with three matches (287 bp) and five medium scaffolds with two matches (between 740 and 2400 bp). We finally have 632 scaffolds with on match in a broad range of sizes (from 100 bp to 33.2 kbp). 

```{r blast2Result, fig.cap="Number of match with Torroba consensus reads vs gene width.", fig.height=4}
blast <- read_tsv(file.path(path, "Ivan_Olsson_pool", 
                            "blast_result_firstline.txt"), col_names = F)
names(blast) <- c("Read", "Scaffold", "Perc_Ident", "Alignment_length", "Mismatches",
                  "Gap_openings", "R_start", "R_end", "S_start", "S_end", "E", "Bits")
scf <- readDNAStringSet(file.path(path, "Ivan_Olsson_pool", "selected_scaffolds.fa"))
blast %>%
  dplyr::left_join(data.frame(Scaffold = names(scf), width = width(scf))) %>% 
  select(Scaffold, Read, width) %>%
  unique() %>%
  group_by(Scaffold, width) %>%
  summarise(n = n()) %>% 
  ggplot(aes(width, n)) +
  geom_point() +
  geom_jitter() +
  ylab("Number of match with Torroba consensus reads") +
  xlab("Scaffold width (bp)") +
  scale_x_log10()
```

## Post-blast extended scaffolds creation 

**Still we must kept in mind that they might be overlap between those scaffolds because they come from two different assemblies**. Consequently we can further try the extended scaffolds creation with this subset. Using @Olsson2017 as the reference and Scotti *et al (in prep)* as the query, with only one run of [quickmerge](https://github.com/mahulchak/quickmerge), we obtained **6** scaffolds from Scotti *et al (in prep)* overlapping on scaffolds from @Olsson2017 with **4** major overlaps (table \@ref(tab:overlpas)). It's relatively few compare to the total of *638* selected scaffolds, which conseuqently do not change much available scaffolds.

```{r assemblyPrep}
dir.create(file.path(path, "Ivan_Olsson_pool", "extended_scaffolds"))
scf_Ivan <- scf[grep("Ivan", names(scf)),]
scf_Olsson <- scf[grep("Olsson", names(scf)),]
writeXStringSet(scf_Ivan, file.path(path, "Ivan_Olsson_pool", "extended_scaffolds",
                                    "selected_scaffolds_Ivan.fa"))
writeXStringSet(scf_Olsson, file.path(path, "Ivan_Olsson_pool", "extended_scaffolds",
                                      "selected_scaffolds_Olsson.fa"))
```

```{bash assemblyMerge2, eval=F, echo=T}
cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_Olsson_pool/extended_scaffolds
nucmer -l 100 -prefix out selected_scaffolds_Olsson.fa selected_scaffolds_Ivan.fa
delta-filter -i 95 -r -q out.delta > out.rq.delta
~/Tools/quickmerge/quickmerge -d out.rq.delta -q selected_scaffolds_Ivan.fa -r selected_scaffolds_Olsson.fa -hco 5.0 -c 1.5 -l n -ml m
```

```{r overlpas}
read_tsv(file.path(path, "Ivan_Olsson_pool", "extended_scaffolds",
                                    "summaryOut.txt")) %>% 
  select(REF, QUERY, OVERLAP_LEN) %>% 
  mutate(REF = gsub("Olsson_2017_", "", REF)) %>% 
  mutate(QUERY = gsub("Ivan_2018_sympho47_", "", QUERY)) %>% 
  rename(Olsson = REF, Scotti = QUERY, "Overlap length" = OVERLAP_LEN) %>% 
  kable(caption = "Overlap between scaffolds of @Olsson2017 and Scotti *et al (in prep)* among selected scaffolds.")
```

